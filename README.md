<p align=center>
  <a href="https://github.com/EscapeLife/love_girlfriend.git">
    <img src="https://escapelife-1257414824.cos.ap-shanghai.myqcloud.com/never-forget-why-you-started.gif" width="680" height="120" alt="Raspi-X" >
  </a>
</p>

<p align=center>
  <b>web-crawler-guide 🕷 使用Python写网络爬虫</b>
</p>

<p align="center">
  <a href="https://github.com/EscapeLife/awesome-builder.git"><img src="https://img.shields.io/badge/Project-web_crawler_guide-green.svg?style=for-the-badge&logo=ubuntu" alt="love_girlfriend"></a>
  <a href="https://github.com/EscapeLife/awesome-builder.git"><img src="https://img.shields.io/badge/Author-Escape-orange.svg?style=for-the-badge&logo=vim" alt="love_girlfriend"></a>
  <a href="https://github.com/EscapeLife/awesome-builder.git"><img src="https://img.shields.io/badge/Languages-Python3.7-yellow.svg?style=for-the-badge&logo=python" alt="love_girlfriend"></a>
</p>

<p align=center>
  <a href="https://github.com/EscapeLife/DotFiles.git">
    <img src="https://github.com/EscapeLife/web-crawler-guide/blob/master/images/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%8C%87%E5%8C%97.png" >
  </a>
</p>

## 1. 目录结构

> **主要从以下几个章节进行讲解**

- [0. 基础知识](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp0/README.md)
- [1. 爬虫介绍](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp1/README.md)
- [2. 数据爬取](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp2/README.md)
- [3. 下载缓存](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp3/README.md)
- [4. 并发下载](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp4/README.md)
- [5. 动态内容](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp5/README.md)
- [6. 表单交互](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp6/README.md)
- [7. 验证码处理](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp7/README.md)
- [8. Scrapy框架](https://github.com/EscapeLife/web-crawler-guide/blob/master/content/chp8/README.md)
- [9. 综合应用](https://github.com/EscapeLife/weWebCrawlerb-crawler-guide/blob/master/content/chp9/README.md)

## 2. 常用三方库

> **写爬虫项目的时候可与借鉴和参考的一些第三方库**

- [faker - 用于生成假数据的库](https://github.com/joke2k/faker)
- [fake-useragent - 伪装浏览器身份(代码量小可阅读源码)](https://github.com/hellysmile/fake-useragent)
- [fuck-login - 模拟登录一些知名的网站](https://github.com/xchaoinfo/fuck-login)
- [awesome-python-login-model - 模拟登陆一些大型网站](https://github.com/Kr1s77/awesome-python-login-model)
- [proxy_pool - 通过网络爬虫抓取互联网上免费的代理IP地址自建代理IP池服务](https://github.com/jhao104/proxy_pool)
- [weibospider - 分布式微博爬虫并支持快速抓取和稳定抓取两种运行模式](https://github.com/SpiderClub/weibospider)
- [webster - 可以抓取网页中AJAX异步内容的分布式爬虫框架](https://github.com/zhuyingda/webster)
- [PSpider - 简单易用的Python爬虫框架](https://github.com/xianhu/PSpider)
- [HAipproxy - 使用Scrapy＋Redis实现的高可用分布式IP代理池](https://github.com/SpiderClub/haipproxy)
- [awesome-spider - 收集各种爬虫项目](https://github.com/facert/awesome-spider)
- [12306 - 12306网站智能刷票订票](https://github.com/testerSunshine/12306)
- [python-spider - Python3网络爬虫实战](https://github.com/Jack-Cherish/python-spider)

## 3. 实现目标

> **光说不练，之后要用的时候还是不会的**

- **爬取Boss直聘Python项目的工具招聘信息**
- **开发基于WEB界面的爬虫项目(可以延续Boss直聘的爬虫)**

## 4. 联系方式

<p align="center">
    <img src="https://escapelife-1257414824.cos.ap-shanghai.myqcloud.com/escape-wechat-qrcode-1.gif" width="280" height="280" alt="WX" align="left" />
</p>

- **💭 [Name] 💭**
  - 🐠 **[`EscapeLife`](https://www.escapelife.site)** 😏
- **💭 [Induction] 💭**
  - 🏦 **[`Focusing P.A.I`](https://www.paodingai.com)** 😂
- **💭 [Email] 💭**
  - 📫 **[`wenpanhappy@gmail.com`](https://www.escapelife.site)** 🤔
- **💭 [Myblog] 💭**
  - 🍺 **[`https://www.escapelife.site`](https://www.escapelife.site)** 😚
- **💭 [License] 💭**
  - 🚧 [**`Apache License, Version 2.0`**](http://www.apache.org/licenses/LICENSE-2.0.html)😝
